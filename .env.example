# ==============================================
# Vision Language Models - Environment Configuration
# ==============================================
# Copy this file to .env and fill in your actual values
# DO NOT commit .env to version control

# ==============================================
# OpenAI CLIP Configuration
# ==============================================
# Model name: ViT-B/32, ViT-B/16, ViT-L/14, etc.
CLIP_MODEL_NAME=ViT-B/32

# Device: cuda, cpu, or mps (for Apple Silicon)
CLIP_DEVICE=cuda

# Optional: Hugging Face API Token for downloading models
CLIP_HF_TOKEN=your_huggingface_token_here

# ==============================================
# LLaVA Configuration
# ==============================================
# Path to LLaVA model (local or Hugging Face)
LLAVA_MODEL_PATH=liuhaotian/llava-v1.5-7b

# API Key (if using hosted LLaVA service)
LLAVA_API_KEY=your_llava_api_key_here

# Device configuration
LLAVA_DEVICE=cuda

# Model precision: fp16, fp32, int8
LLAVA_PRECISION=fp16

# ==============================================
# BLIP-2 Configuration
# ==============================================
# Model type: Salesforce/blip2-opt-2.7b, Salesforce/blip2-flan-t5-xl, etc.
BLIP2_MODEL_TYPE=Salesforce/blip2-opt-2.7b

# API Key (if using hosted BLIP-2 service)
BLIP2_API_KEY=your_blip2_api_key_here

# Device configuration
BLIP2_DEVICE=cuda

# Hugging Face token (optional)
BLIP2_HF_TOKEN=your_huggingface_token_here

# ==============================================
# CogVLM Configuration
# ==============================================
# Path to CogVLM model
COGVLM_MODEL_PATH=THUDM/cogvlm-chat-hf

# API Key (if using hosted CogVLM service)
COGVLM_API_KEY=your_cogvlm_api_key_here

# Device configuration
COGVLM_DEVICE=cuda

# Model precision
COGVLM_PRECISION=fp16

# Quantization: none, int8, int4
COGVLM_QUANTIZATION=none

# ==============================================
# General Settings
# ==============================================
# Maximum batch size for inference
MAX_BATCH_SIZE=32

# Cache directory for downloaded models
CACHE_DIR=./model_cache

# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Maximum image size (pixels)
MAX_IMAGE_SIZE=1024

# Number of worker threads
NUM_WORKERS=4

# ==============================================
# API Configuration (Optional)
# ==============================================
# If exposing as API service
API_HOST=0.0.0.0
API_PORT=8000
API_KEY=your_api_key_here

# ==============================================
# Hugging Face Hub Configuration
# ==============================================
# Main Hugging Face token for all models
HUGGINGFACE_TOKEN=your_huggingface_token_here

# Cache directory for Hugging Face models
HF_HOME=./hf_cache

# ==============================================
# Advanced Settings
# ==============================================
# Enable mixed precision training
ENABLE_AMP=true

# Gradient accumulation steps
GRADIENT_ACCUMULATION_STEPS=1

# Enable model compilation (PyTorch 2.0+)
ENABLE_COMPILE=false
